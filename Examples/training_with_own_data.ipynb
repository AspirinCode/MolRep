{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from MolRep import MolRep\n",
    "from MolRep.Utils.logger import Logger\n",
    "from MolRep.Utils.config_from_dict import Config\n",
    "from MolRep.Experiments.experiments import EndToEndExperiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CONFIG_DIR = '../MolRep/Configs' # Need to set! The directory of Model Configurations files, such as config_CMPNN.yml.\n",
    "OUTPUT_DIR = '../Outputs/'\n",
    "\n",
    "\n",
    "_CONFIG_BASE = 'config_'\n",
    "_CONFIG_FILENAME = 'config_results.json'\n",
    "\n",
    "_FOLDS = 5\n",
    "MODEL_NAME = 'CMPNN'\n",
    "\n",
    "# define your dataset name\n",
    "DATASET_NAME = 'BBB'  \n",
    "# define the PATH of your data. Could be CSV or SDF format.\n",
    "DATASET_PATH = '../MolRep/Datasets/BBBP/BBBP.csv'\n",
    "# define the column name of SMILES in your data\n",
    "SMILES_COLUMN = 'smiles'\n",
    "# the column names of TARGET NAME in your data. Must be a List.\n",
    "TARGET_COLUMNS = ['p_np']\n",
    "# define the task type. Classification or Regression\n",
    "TASK_TYPE = 'Classification'\n",
    "# define the metric type, such as auc or rmse\n",
    "METRIC_TYPE = 'auc'\n",
    "# define the split data type, such as random, stratified, scaffold. NOTE that stratified only applies to single property\n",
    "SPLIT_TYPE = 'random'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config, dataset, model_configurations, model_selector, exp_path = MolRep.construct_dataset(\n",
    "    dataset_name = DATASET_NAME,\n",
    "    model_name = MODEL_NAME,\n",
    "    dataset_path = DATASET_PATH,\n",
    "    smiles_column = SMILES_COLUMN,\n",
    "    target_columns = TARGET_COLUMNS,\n",
    "    task_type = TASK_TYPE,\n",
    "    metric_type = METRIC_TYPE,\n",
    "    split_type = SPLIT_TYPE,\n",
    "    inner_k = _FOLDS,\n",
    "    config_dir = MODEL_CONFIG_DIR,\n",
    "    output_dir=OUTPUT_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_id = 0   # the idx of model configs since there are more than 100 combinations of hyper-parameters.\n",
    "KFOLD_FOLDER = os.path.join(exp_path, str(_FOLDS) + '_FOLD_MS')\n",
    "exp_config_name = os.path.join(KFOLD_FOLDER, _CONFIG_BASE + str(config_id + 1))\n",
    "config_filename = os.path.join(exp_config_name, _CONFIG_FILENAME)\n",
    "if not os.path.exists(exp_config_name):\n",
    "    os.makedirs(exp_config_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration: {'model': 'CMPNN', 'device': 'cuda', 'batch_size': 50, 'learning_rate': 0.0001, 'l2': 0, 'hidden_size': 300, 'bias': False, 'depth': 3, 'dropout': 0.0, 'activation': 'ReLU', 'undirected': False, 'ffn_hidden_size': 256, 'ffn_num_layers': 2, 'atom_messages': False, 'no_cache': False, 'optimizer': 'Adam', 'scheduler': {'class': 'NoamLR', 'args': {'warmup_epochs': [2.0], 'step_size': 10, 'max_lr': [0.0001], 'init_lr': [1e-05], 'final_lr': [1e-05]}}, 'early_stopper': {'class': 'Patience', 'args': {'patience': 500, 'use_loss': False}}, 'gradient_clipping': None, 'num_epochs': 30, 'num_lrs': 1, 'features_only': False, 'atom_descriptors': 'None', 'use_input_features': False, 'shuffle': True}\n"
     ]
    }
   ],
   "source": [
    "config = model_configurations[config_id]\n",
    "\n",
    "# model configs could be change\n",
    "# for example:\n",
    "# config['device'] = 'cpu' or config['batch_size'] = 32\n",
    "\n",
    "logger = Logger(str(os.path.join(exp_config_name, 'experiment.log')), mode='w')\n",
    "logger.log('Configuration: ' + str(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold_dict = {\n",
    "    'config': config,\n",
    "    'folds': [{} for _ in range(_FOLDS)],\n",
    "    'avg_TR_score': 0.,\n",
    "    'avg_VL_score': 0.,\n",
    "    'std_TR_score': 0.,\n",
    "    'std_VL_score': 0.\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training in Fold: 1\n",
      "[TRAIN] Epoch: 1, train loss: 0.603535 train auc: 0.519052\n",
      "[VALID] Epoch: 1, valid loss: 0.574165 valid auc: 0.590566\n",
      "- Elapsed time: 8.67s , Time estimation in a fold: 4.33min\n",
      "[TRAIN] Epoch: 10, train loss: 0.338314 train auc: 0.891489\n",
      "[VALID] Epoch: 10, valid loss: 0.511618 valid auc: 0.864862\n",
      "- Elapsed time: 2.39s , Time estimation in a fold: 1.19min\n",
      "[TRAIN] Epoch: 20, train loss: 0.217411 train auc: 0.956670\n",
      "[VALID] Epoch: 20, valid loss: 0.479814 valid auc: 0.924324\n",
      "- Elapsed time: 2.30s , Time estimation in a fold: 1.15min\n",
      "[TRAIN] Epoch: 30, train loss: 0.147633 train auc: 0.980445\n",
      "[VALID] Epoch: 30, valid loss: 0.465639 valid auc: 0.948089\n",
      "- Elapsed time: 2.58s , Time estimation in a fold: 1.29min\n",
      "1 split, TR Score: 0.9804451175901384 VL Score: 0.9480893073126082\n",
      "Training in Fold: 2\n",
      "[TRAIN] Epoch: 1, train loss: 0.591510 train auc: 0.503150\n",
      "[VALID] Epoch: 1, valid loss: 0.549290 valid auc: 0.680348\n",
      "- Elapsed time: 2.65s , Time estimation in a fold: 1.32min\n",
      "[TRAIN] Epoch: 10, train loss: 0.253530 train auc: 0.942107\n",
      "[VALID] Epoch: 10, valid loss: 0.460531 valid auc: 0.960862\n",
      "- Elapsed time: 2.58s , Time estimation in a fold: 1.29min\n",
      "[TRAIN] Epoch: 20, train loss: 0.138999 train auc: 0.982137\n",
      "[VALID] Epoch: 20, valid loss: 0.448556 valid auc: 0.961660\n",
      "- Elapsed time: 2.55s , Time estimation in a fold: 1.27min\n",
      "[TRAIN] Epoch: 30, train loss: 0.060382 train auc: 0.994522\n",
      "[VALID] Epoch: 30, valid loss: 0.448552 valid auc: 0.946858\n",
      "- Elapsed time: 2.17s , Time estimation in a fold: 1.08min\n",
      "2 split, TR Score: 0.9691965729736006 VL Score: 0.9662703227371998\n",
      "Training in Fold: 3\n",
      "[TRAIN] Epoch: 1, train loss: 0.541277 train auc: 0.572703\n",
      "[VALID] Epoch: 1, valid loss: 0.568227 valid auc: 0.766564\n",
      "- Elapsed time: 2.17s , Time estimation in a fold: 1.08min\n",
      "[TRAIN] Epoch: 10, train loss: 0.215546 train auc: 0.957976\n",
      "[VALID] Epoch: 10, valid loss: 0.474930 valid auc: 0.944316\n",
      "- Elapsed time: 2.57s , Time estimation in a fold: 1.28min\n",
      "[TRAIN] Epoch: 20, train loss: 0.116960 train auc: 0.986896\n",
      "[VALID] Epoch: 20, valid loss: 0.457537 valid auc: 0.961970\n",
      "- Elapsed time: 2.98s , Time estimation in a fold: 1.49min\n",
      "[TRAIN] Epoch: 30, train loss: 0.061614 train auc: 0.994492\n",
      "[VALID] Epoch: 30, valid loss: 0.453324 valid auc: 0.963123\n",
      "- Elapsed time: 2.35s , Time estimation in a fold: 1.17min\n",
      "3 split, TR Score: 0.9917928411576323 VL Score: 0.9653018069973087\n",
      "Training in Fold: 4\n",
      "[TRAIN] Epoch: 1, train loss: 0.554342 train auc: 0.535977\n",
      "[VALID] Epoch: 1, valid loss: 0.569632 valid auc: 0.749928\n",
      "- Elapsed time: 2.97s , Time estimation in a fold: 1.48min\n",
      "[TRAIN] Epoch: 10, train loss: 0.204911 train auc: 0.962274\n",
      "[VALID] Epoch: 10, valid loss: 0.471448 valid auc: 0.939965\n",
      "- Elapsed time: 2.74s , Time estimation in a fold: 1.37min\n",
      "[TRAIN] Epoch: 20, train loss: 0.119953 train auc: 0.986013\n",
      "[VALID] Epoch: 20, valid loss: 0.460950 valid auc: 0.950820\n",
      "- Elapsed time: 2.53s , Time estimation in a fold: 1.26min\n",
      "[TRAIN] Epoch: 30, train loss: 0.051065 train auc: 0.996342\n",
      "[VALID] Epoch: 30, valid loss: 0.453020 valid auc: 0.947398\n",
      "- Elapsed time: 2.86s , Time estimation in a fold: 1.43min\n",
      "4 split, TR Score: 0.9907285750614563 VL Score: 0.9547509151679134\n",
      "Training in Fold: 5\n",
      "[TRAIN] Epoch: 1, train loss: 0.575922 train auc: 0.520600\n",
      "[VALID] Epoch: 1, valid loss: 0.541074 valid auc: 0.698732\n",
      "- Elapsed time: 2.71s , Time estimation in a fold: 1.35min\n",
      "[TRAIN] Epoch: 10, train loss: 0.206949 train auc: 0.963929\n",
      "[VALID] Epoch: 10, valid loss: 0.436561 valid auc: 0.973021\n",
      "- Elapsed time: 2.56s , Time estimation in a fold: 1.28min\n",
      "[TRAIN] Epoch: 20, train loss: 0.096340 train auc: 0.989606\n",
      "[VALID] Epoch: 20, valid loss: 0.428705 valid auc: 0.976338\n",
      "- Elapsed time: 2.18s , Time estimation in a fold: 1.09min\n",
      "[TRAIN] Epoch: 30, train loss: 0.069825 train auc: 0.994335\n",
      "[VALID] Epoch: 30, valid loss: 0.435798 valid auc: 0.962885\n",
      "- Elapsed time: 3.12s , Time estimation in a fold: 1.56min\n",
      "5 split, TR Score: 0.9833488533917295 VL Score: 0.9781807459826036\n",
      "TR avg is 0.9831 std is 0.0082; VL avg is 0.9625 std is 0.0104\n"
     ]
    }
   ],
   "source": [
    "dataset_getter = MolRep.construct_dataloader(dataset)\n",
    "for k in range(_FOLDS):\n",
    "    logger.log(f\"Training in Fold: {k+1}\")\n",
    "    dataset_getter.set_inner_k(k)\n",
    "\n",
    "    fold_exp_folder = os.path.join(exp_config_name, 'FOLD_' + str(k + 1))\n",
    "    # Create the experiment object which will be responsible for running a specific experiment\n",
    "    experiment = EndToEndExperiment(config, dataset_config, fold_exp_folder)\n",
    "\n",
    "    model_path = os.path.join(fold_exp_folder, f\"{MODEL_NAME}_{DATASET_NAME}_fold_{k}.pt\")\n",
    "    training_score, validation_score = experiment.run_valid(dataset_getter, logger, other={'model_path': model_path})\n",
    "\n",
    "    # print('training_score:', training_score, 'validation_score:',validation_score)\n",
    "    logger.log(str(k+1) + ' split, TR Score: ' + str(training_score) +\n",
    "                ' VL Score: ' + str(validation_score))\n",
    "\n",
    "    k_fold_dict['folds'][k]['TR_score'] = training_score\n",
    "    k_fold_dict['folds'][k]['VL_score'] = validation_score\n",
    "\n",
    "tr_scores = np.array([k_fold_dict['folds'][k]['TR_score'] for k in range(_FOLDS)])\n",
    "vl_scores = np.array([k_fold_dict['folds'][k]['VL_score'] for k in range(_FOLDS)])\n",
    "\n",
    "k_fold_dict['avg_TR_score'] = tr_scores.mean()\n",
    "k_fold_dict['std_TR_score'] = tr_scores.std()\n",
    "k_fold_dict['avg_VL_score'] = vl_scores.mean()\n",
    "k_fold_dict['std_VL_score'] = vl_scores.std()\n",
    "\n",
    "log_str = f\"TR avg is %.4f std is %.4f; VL avg is %.4f std is %.4f\" % (\n",
    "            k_fold_dict['avg_TR_score'], k_fold_dict['std_TR_score'], k_fold_dict['avg_VL_score'], k_fold_dict['std_VL_score']\n",
    "        )\n",
    "logger.log(log_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:MolRep]",
   "language": "python",
   "name": "conda-env-MolRep-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
